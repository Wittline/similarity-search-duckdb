{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "4kkuZ6Cpwx5b"
      },
      "source": [
        "# Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-r0L-ANt-km"
      },
      "outputs": [],
      "source": [
        "pip install duckdb==0.8.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jv5LIiPkuK8d"
      },
      "outputs": [],
      "source": [
        "pip install -U sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "RwuBnKJ4uNTw"
      },
      "outputs": [],
      "source": [
        "import duckdb\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "from collections import OrderedDict\n",
        "import itertools"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "kd91JDJqw9iH"
      },
      "source": [
        "# similaritySearch class\n",
        "\n",
        "- The ***similaritySearch*** class by default creates a table called \"VECTORS\" where all records from all tables are stored as vectors. This happens within the ***__create_vector_storage*** and ***insert_vector*** methods.\n",
        "\n",
        "- There is a method called ***__to_vector*** that converts each incoming record from any table into a vector. Here, a pretrained model is used to have universal vectors that do not depend on the corpus of other incoming records. Techniques like ***word2vec***, ***tfidf***, ***bag of words**, and others would not be suitable as they require knowledge of all incoming records to generate a vector.\n",
        "\n",
        "- The ***search_similarities*** method is not efficient because it only uses duckdb as a storage for vectors. The similarity computation is not done within the duckdb engine. Instead, all vectors are extracted and compared locally to measure the distance between the input row and existing vectors. It was not possible for me to create a scalar function to offload this computation to the engine.\n",
        "\n",
        "- The cosine metric is used within the ***__cosine_distance_similarity*** method. The decision to use this metric is based on its good results for many types of cases and its insensitivity to vector length. The similarity between two words decreases as the distance between their vectors increases, and vice versa. Therefore, a value close to 0 indicates a good similarity between the input row and the current vector being compared.\n",
        "\n",
        "- The remaining methods handle the logic for inserting tables and inserting data into existing tables.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "z9TlXx0zt4-O"
      },
      "outputs": [],
      "source": [
        "class similaritySearch:\n",
        "                \n",
        "    def __init__(self, database_name):\n",
        "        self.database_name = database_name\n",
        "        self.con = duckdb.connect(database_name)\n",
        "        self.__create_vector_storage()\n",
        "\n",
        "    def __execute_commit(self, statement):        \n",
        "        self.con.execute(statement)\n",
        "        self.con.commit()        \n",
        "\n",
        "    def __create_vector_storage(self, ):\n",
        "        statement = '''CREATE TABLE IF NOT EXISTS VECTORS (id INTEGER, tbl VARCHAR, vector DOUBLE[])'''\n",
        "        self.__execute_commit(statement)\n",
        "\n",
        "    def create_table(self, schema):\n",
        "        metadata = ', '.join([k + ' ' + v for k, v in schema['columns'].items()])\n",
        "        statement = \"CREATE TABLE IF NOT EXISTS {} ({})\".format(schema['table_name'],metadata)\n",
        "        self.__execute_commit(statement)\n",
        "\n",
        "\n",
        "    def insert_data(self, table_name,  schema):\n",
        "        columns = ', '.join(schema.keys())\n",
        "        holders = ', '.join([f\"'{v}'\" if isinstance(v, str) else str(v) for v in schema.values()])\n",
        "        statement = f\"INSERT INTO {table_name} ({columns}) VALUES ({holders})\"\n",
        "        self.__execute_commit(statement)\n",
        "        vector = self.__to_vector(holders)\n",
        "        return vector\n",
        "        \n",
        "\n",
        "    def insert_vector(self, id, table_name, vector):\n",
        "        statement = f\"INSERT INTO VECTORS (id, tbl, vector) VALUES ({id}, '{table_name}', {vector})\"\n",
        "        self.__execute_commit(statement)\n",
        "\n",
        "\n",
        "    def __to_vector(self, data):\n",
        "        model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2', device='cpu', cache_folder='/')\n",
        "        embeddings = model.encode(data, convert_to_tensor=True, normalize_embeddings=True)                \n",
        "        return embeddings.tolist()\n",
        "\n",
        "    def __cosine_distance_similarity(self, u, v):\n",
        "        distance = 1.0 - (np.dot(u, v)/\n",
        "                          (np.sqrt(sum(np.square(u))) * \n",
        "                           np.sqrt(sum(np.square(v))))\n",
        "                          )\n",
        "        return distance\n",
        "\n",
        "\n",
        "    def __value(self, item):\n",
        "        return item[1]    \n",
        "\n",
        "    def search_similarities(self, query, table_name, top_k):\n",
        "\n",
        "        sd = OrderedDict()\n",
        "\n",
        "        holders = ', '.join([f\"'{v}'\" if isinstance(v, str) else str(v) for v in query.values()])\n",
        "        query_vector = self.__to_vector(holders)\n",
        "\n",
        "        rows =  self.con.execute(f\"SELECT id, vector FROM VECTORS WHERE tbl = '{table_name}'\")\n",
        "    \n",
        "        for row in rows.fetchall():            \n",
        "            d = self.__cosine_distance_similarity(query_vector, row[1])            \n",
        "            sd[row[0]] = d\n",
        "\n",
        "        sd = OrderedDict(sorted(sd.items(), key=self.__value))\n",
        "\n",
        "        return list(itertools.islice(sd.items(), top_k))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "JgnYsIaT6WNe"
      },
      "source": [
        "# DB is an object of the class similaritySearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-TCPjHT1u8Og"
      },
      "outputs": [],
      "source": [
        "db = similaritySearch(':memory:')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "HvotstZ76agT"
      },
      "source": [
        "# The dictionary ***schema_tables*** contains the schema of all the tables to be created."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "GWAG4WnXvKwP"
      },
      "outputs": [],
      "source": [
        "schema_tables = [{\n",
        "    \"table_name\": \"MyTable\",\n",
        "    \"columns\": {\n",
        "        \"id\": 'INTEGER',\n",
        "        \"column1\": \"VARCHAR\",\n",
        "        \"column2\": \"VARCHAR\",\n",
        "        \"column3\": \"VARCHAR\",\n",
        "        \"column4\": \"INTEGER\"\n",
        "    }\n",
        "}]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "5ygujOJa6rZ_"
      },
      "source": [
        "# We iterate through each element and create the tables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uF3JJcFavOrg",
        "outputId": "bcd12478-3d62-40d4-a562-69a843262194"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Table MyTable created\n"
          ]
        }
      ],
      "source": [
        "for schema in schema_tables:\n",
        "    db.create_table(schema)\n",
        "    print(f\"Table {schema['table_name']} created\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "kgw4rjoz7LCQ"
      },
      "source": [
        "# The dictionary ***data_tables*** contains the data to be added to each table."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "sGnn_ZwguSnR"
      },
      "outputs": [],
      "source": [
        "data_tables = [{\n",
        "\"table_name\": \"MyTable\",\n",
        "    \"data\":{\n",
        "            \"id\":5,\n",
        "            \"column1\":\"Random text for testing - movies\",\n",
        "            \"column2\":\"movies\",\n",
        "            \"column3\":\"Run Lola Run\",\n",
        "            \"column4\": 112\n",
        "        }\n",
        "    },\n",
        "\n",
        "{\n",
        "\"table_name\": \"MyTable\",\n",
        "    \"data\":{\n",
        "            \"id\":6,\n",
        "            \"column1\":\"Random text for testing - food\",\n",
        "            \"column2\":\"food\",\n",
        "            \"column3\":\"Bratwurst\",\n",
        "            \"column4\": 115\n",
        "        }\n",
        "    },\n",
        "{\n",
        "\"table_name\": \"MyTable\",\n",
        "    \"data\":{\n",
        "            \"id\":7,\n",
        "            \"column1\":\"Random text for testing - place\",\n",
        "            \"column2\":\"place\",\n",
        "            \"column3\":\"Neuschwanstein Castle\",\n",
        "            \"column4\": 123\n",
        "        }\n",
        "    },\n",
        "{\n",
        "\"table_name\": \"MyTable\",\n",
        "    \"data\":{\n",
        "            \"id\":8,\n",
        "            \"column1\":\"skjdlkajsasdf\",\n",
        "            \"column2\":\"dasñldk´ñalskd\",\n",
        "            \"column3\":\"dasd\",\n",
        "            \"column4\": 580\n",
        "        }\n",
        "    }, \n",
        "{\n",
        "\"table_name\": \"MyTable\",\n",
        "    \"data\":{\n",
        "            \"id\":9,\n",
        "            \"column1\":\"aaaaaaaaaaaaaa\",\n",
        "            \"column2\":\"33333333errrrrrrrrrr\",\n",
        "            \"column3\":\"fgggggggggggg\",\n",
        "            \"column4\": 111\n",
        "        }\n",
        "    }                \n",
        "]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "NOAJBu577ja5"
      },
      "source": [
        "# We iterate and insert the data into each table while simultaneously creating a vector for each added record.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2E1hpG_gvmlF",
        "outputId": "76dadd2b-20b0-4847-9787-3343e4366316"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "record inserted in table MyTable\n",
            "vector inserted\n",
            "record inserted in table MyTable\n",
            "vector inserted\n",
            "record inserted in table MyTable\n",
            "vector inserted\n",
            "record inserted in table MyTable\n",
            "vector inserted\n",
            "record inserted in table MyTable\n",
            "vector inserted\n"
          ]
        }
      ],
      "source": [
        "for data in data_tables:\n",
        "    vector = db.insert_data(data['table_name'], data['data'])\n",
        "    print(f\"record inserted in table {data['table_name']}\")\n",
        "    db.insert_vector(data['data']['id'],data['table_name'], vector )\n",
        "    print(f\"vector inserted\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "pBIHXgLl74NW"
      },
      "source": [
        "# Here I'm simply requesting to display the 3 most similar vectors to an query or input vector, and clearly the results look quite good. The example below shows that the 3 most similar records are the records with id 8, 9, and 7."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yQb1azWvnvy",
        "outputId": "337c9f49-ef46-4dbc-d0f0-50865bbe13c2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(8, 0.07260156684169694), (9, 0.48166218516862114), (7, 0.5649090819336836)]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query = {\"column1\": \"skjdlkajsasdf\", \"column2\": \"dasñldk´ñalskd\", \"column3\": \"dasd\", \"column4\": 580}\n",
        "similarities = db.search_similarities(query, \"MyTable\", top_k=3)\n",
        "similarities"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
